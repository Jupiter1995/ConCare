{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T02:11:20.230506Z",
     "start_time": "2021-11-02T02:11:17.941835Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import imp\n",
    "import re\n",
    "import pickle\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from utils import utils\n",
    "from utils.readers import InHospitalMortalityReader\n",
    "from utils.preprocessing import Discretizer, Normalizer\n",
    "from utils import metrics\n",
    "from utils import common_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T02:11:20.237620Z",
     "start_time": "2021-11-02T02:11:20.234044Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = './data/'\n",
    "data_in_hosp = os.path.join(data_path, 'in-hospital-mortality')\n",
    "file_name = './model/concare0'\n",
    "small_part = False\n",
    "arg_timestep = 1.0\n",
    "batch_size = 256\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T02:11:20.399479Z",
     "start_time": "2021-11-02T02:11:20.239796Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build readers, discretizers, normalizers\n",
    "train_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data_in_hosp, 'train'),\n",
    "                                         listfile=os.path.join(data_in_hosp, 'train_listfile.csv'),\n",
    "                                         period_length=48.0)\n",
    "\n",
    "val_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data_in_hosp, 'train'),\n",
    "                                       listfile=os.path.join(data_in_hosp, 'val_listfile.csv'),\n",
    "                                       period_length=48.0)\n",
    "\n",
    "discretizer = Discretizer(timestep=arg_timestep,\n",
    "                          store_masks=True,\n",
    "                          impute_strategy='previous',\n",
    "                          start_time='zero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T02:11:20.411518Z",
     "start_time": "2021-11-02T02:11:20.401666Z"
    }
   },
   "outputs": [],
   "source": [
    "discretizer_header = discretizer.transform(train_reader.read_example(0)[\"X\"])[1].split(',')\n",
    "cont_channels = [i for (i, x) in enumerate(discretizer_header) if x.find(\"->\") == -1]\n",
    "\n",
    "normalizer = Normalizer(fields=cont_channels)  # choose here which columns to standardize\n",
    "normalizer_state = 'ihm_normalizer'\n",
    "normalizer_state = os.path.join(os.path.dirname(data_in_hosp), normalizer_state)\n",
    "normalizer.load_params(normalizer_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T02:12:44.729970Z",
     "start_time": "2021-11-02T02:11:20.413422Z"
    }
   },
   "outputs": [],
   "source": [
    "n_trained_chunks = 0\n",
    "train_raw = utils.load_data(train_reader, discretizer, normalizer, small_part, return_names=True)\n",
    "val_raw = utils.load_data(val_reader, discretizer, normalizer, small_part, return_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T02:12:48.064359Z",
     "start_time": "2021-11-02T02:12:44.733279Z"
    }
   },
   "outputs": [],
   "source": [
    "demographic_data = []\n",
    "diagnosis_data = []\n",
    "idx_list = []\n",
    "\n",
    "demo_path = data_path + 'demographic/'\n",
    "for cur_name in os.listdir(demo_path):\n",
    "    cur_id, cur_episode = cur_name.split('_', 1)\n",
    "    cur_episode = cur_episode[:-4]\n",
    "    cur_file = demo_path + cur_name\n",
    "\n",
    "    with open(cur_file, \"r\") as tsfile:\n",
    "        header = tsfile.readline().strip().split(',')\n",
    "        if header[0] != \"Icustay\":\n",
    "            continue\n",
    "        cur_data = tsfile.readline().strip().split(',')\n",
    "        \n",
    "    if len(cur_data) == 1:\n",
    "        cur_demo = np.zeros(12)\n",
    "        cur_diag = np.zeros(128)\n",
    "    else:\n",
    "        if cur_data[3] == '':\n",
    "            cur_data[3] = 60.0\n",
    "        if cur_data[4] == '':\n",
    "            cur_data[4] = 160\n",
    "        if cur_data[5] == '':\n",
    "            cur_data[5] = 60\n",
    "\n",
    "        cur_demo = np.zeros(12)\n",
    "        cur_demo[int(cur_data[1])] = 1\n",
    "        cur_demo[5 + int(cur_data[2])] = 1\n",
    "        cur_demo[9:] = cur_data[3:6]\n",
    "        cur_diag = np.array(cur_data[8:], dtype=np.int)\n",
    "\n",
    "    demographic_data.append(cur_demo)\n",
    "    diagnosis_data.append(cur_diag)\n",
    "    idx_list.append(cur_id+'_'+cur_episode)\n",
    "\n",
    "for each_idx in range(9,12):\n",
    "    cur_val = []\n",
    "    for i in range(len(demographic_data)):\n",
    "        cur_val.append(demographic_data[i][each_idx])\n",
    "    cur_val = np.array(cur_val)\n",
    "    _mean = np.mean(cur_val)\n",
    "    _std = np.std(cur_val)\n",
    "    _std = _std if _std > 1e-7 else 1e-7\n",
    "    for i in range(len(demographic_data)):\n",
    "        demographic_data[i][each_idx] = (demographic_data[i][each_idx] - _mean) / _std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T02:12:48.079449Z",
     "start_time": "2021-11-02T02:12:48.067022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() == True else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "print(\"available device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T02:12:48.189439Z",
     "start_time": "2021-11-02T02:12:48.082871Z"
    }
   },
   "outputs": [],
   "source": [
    "class SingleAttention(nn.Module):\n",
    "    def __init__(self, attention_input_dim, attention_hidden_dim, attention_type='add', demographic_dim=12, time_aware=False, use_demographic=False):\n",
    "        super(SingleAttention, self).__init__()\n",
    "        \n",
    "        self.attention_type = attention_type\n",
    "        self.attention_hidden_dim = attention_hidden_dim\n",
    "        self.attention_input_dim = attention_input_dim\n",
    "        self.use_demographic = use_demographic\n",
    "        self.demographic_dim = demographic_dim\n",
    "        self.time_aware = time_aware\n",
    "\n",
    "        # batch_time = torch.arange(0, batch_mask.size()[1], dtype=torch.float32).reshape(1, batch_mask.size()[1], 1)\n",
    "        # batch_time = batch_time.repeat(batch_mask.size()[0], 1, 1)\n",
    "        \n",
    "        if attention_type == 'add':\n",
    "            if self.time_aware == True:\n",
    "                # self.Wx = nn.Parameter(torch.randn(attention_input_dim+1, attention_hidden_dim))\n",
    "                self.Wx = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
    "                self.Wtime_aware = nn.Parameter(torch.randn(1, attention_hidden_dim))\n",
    "                nn.init.kaiming_uniform_(self.Wtime_aware, a=math.sqrt(5))\n",
    "            else:\n",
    "                self.Wx = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
    "            self.Wt = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
    "            self.Wd = nn.Parameter(torch.randn(demographic_dim, attention_hidden_dim))\n",
    "            self.bh = nn.Parameter(torch.zeros(attention_hidden_dim,))\n",
    "            self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
    "            self.ba = nn.Parameter(torch.zeros(1,))\n",
    "            \n",
    "            nn.init.kaiming_uniform_(self.Wd, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wx, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wt, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "        elif attention_type == 'mul':\n",
    "            self.Wa = nn.Parameter(torch.randn(attention_input_dim, attention_input_dim))\n",
    "            self.ba = nn.Parameter(torch.zeros(1,))\n",
    "            \n",
    "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "        elif attention_type == 'concat':\n",
    "            if self.time_aware == True:\n",
    "                self.Wh = nn.Parameter(torch.randn(2*attention_input_dim+1, attention_hidden_dim))\n",
    "            else:\n",
    "                self.Wh = nn.Parameter(torch.randn(2*attention_input_dim, attention_hidden_dim))\n",
    "\n",
    "            self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
    "            self.ba = nn.Parameter(torch.zeros(1,))\n",
    "            \n",
    "            nn.init.kaiming_uniform_(self.Wh, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "            \n",
    "        elif attention_type == 'new':\n",
    "            self.Wt = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
    "            self.Wx = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
    "\n",
    "            self.rate = nn.Parameter(torch.zeros(1)+0.8)\n",
    "            nn.init.kaiming_uniform_(self.Wx, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wt, a=math.sqrt(5))\n",
    "            \n",
    "        else:\n",
    "            raise RuntimeError('Wrong attention type.')\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, input, demo=None):\n",
    " \n",
    "        batch_size, time_step, input_dim = input.size() # batch_size * time_step * hidden_dim(i)\n",
    "        #assert(input_dim == self.input_dim)\n",
    "\n",
    "        # time_decays = torch.zeros((time_step,time_step)).to(device)# t*t\n",
    "        # for this_time in range(time_step):\n",
    "        #     for pre_time in range(time_step):\n",
    "        #         if pre_time > this_time:\n",
    "        #             break\n",
    "        #         time_decays[this_time][pre_time] = torch.tensor(this_time - pre_time, dtype=torch.float32).to(device)\n",
    "        # b_time_decays = tile(time_decays, 0, batch_size).view(batch_size,time_step,time_step).unsqueeze(-1).to(device)# b t t 1\n",
    "\n",
    "        time_decays = torch.tensor(range(47,-1,-1), dtype=torch.float32).unsqueeze(-1).unsqueeze(0).to(device)# 1*t*1\n",
    "        b_time_decays = time_decays.repeat(batch_size,1,1)+1# b t 1\n",
    "        \n",
    "        if self.attention_type == 'add': #B*T*I  @ H*I\n",
    "            q = torch.matmul(input[:,-1,:], self.Wt)# b h\n",
    "            q = torch.reshape(q, (batch_size, 1, self.attention_hidden_dim)) #B*1*H\n",
    "            if self.time_aware == True:\n",
    "                # k_input = torch.cat((input, time), dim=-1)\n",
    "                k = torch.matmul(input, self.Wx)#b t h\n",
    "                # k = torch.reshape(k, (batch_size, 1, time_step, self.attention_hidden_dim)) #B*1*T*H\n",
    "                time_hidden = torch.matmul(b_time_decays, self.Wtime_aware)#  b t h\n",
    "            else:\n",
    "                k = torch.matmul(input, self.Wx)# b t h\n",
    "                # k = torch.reshape(k, (batch_size, 1, time_step, self.attention_hidden_dim)) #B*1*T*H\n",
    "            if self.use_demographic == True:\n",
    "                d = torch.matmul(demo, self.Wd) #B*H\n",
    "                d = torch.reshape(d, (batch_size, 1, self.attention_hidden_dim)) # b 1 h\n",
    "            h = q + k + self.bh # b t h\n",
    "            if self.time_aware == True:\n",
    "                h += time_hidden\n",
    "            h = self.tanh(h) #B*T*H\n",
    "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
    "            e = torch.reshape(e, (batch_size, time_step))# b t\n",
    "        elif self.attention_type == 'mul':\n",
    "            e = torch.matmul(input[:,-1,:], self.Wa)#b i\n",
    "            e = torch.matmul(e.unsqueeze(1), input.permute(0,2,1)).squeeze() + self.ba #b t\n",
    "        elif self.attention_type == 'concat':\n",
    "            q = input[:,-1,:].unsqueeze(1).repeat(1,time_step,1)# b t i\n",
    "            k = input\n",
    "            c = torch.cat((q, k), dim=-1) #B*T*2I\n",
    "            if self.time_aware == True:\n",
    "                c = torch.cat((c, b_time_decays), dim=-1) #B*T*2I+1\n",
    "            h = torch.matmul(c, self.Wh)\n",
    "            h = self.tanh(h)\n",
    "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
    "            e = torch.reshape(e, (batch_size, time_step)) # b t \n",
    "            \n",
    "        elif self.attention_type == 'new':\n",
    "            \n",
    "            q = torch.matmul(input[:,-1,:], self.Wt)# b h\n",
    "            q = torch.reshape(q, (batch_size, 1, self.attention_hidden_dim)) #B*1*H\n",
    "            k = torch.matmul(input, self.Wx)#b t h\n",
    "            dot_product = torch.matmul(q, k.transpose(1, 2)).squeeze() # b t\n",
    "            denominator =  self.sigmoid(self.rate) * (torch.log(2.72 +  (1-self.sigmoid(dot_product)))* (b_time_decays.squeeze()))\n",
    "            e = self.relu(self.sigmoid(dot_product)/(denominator)) # b * t\n",
    "#          * (b_time_decays.squeeze())\n",
    "        # e = torch.exp(e - torch.max(e, dim=-1, keepdim=True).values)\n",
    "        \n",
    "        # if self.attention_width is not None:\n",
    "        #     if self.history_only:\n",
    "        #         lower = torch.arange(0, time_step).to(device) - (self.attention_width - 1)\n",
    "        #     else:\n",
    "        #         lower = torch.arange(0, time_step).to(device) - self.attention_width // 2\n",
    "        #     lower = lower.unsqueeze(-1)\n",
    "        #     upper = lower + self.attention_width\n",
    "        #     indices = torch.arange(0, time_step).unsqueeze(0).to(device)\n",
    "        #     e = e * (lower <= indices).float() * (indices < upper).float()\n",
    "        \n",
    "        # s = torch.sum(e, dim=-1, keepdim=True)\n",
    "        # mask = subsequent_mask(time_step).to(device) # 1 t t 下三角\n",
    "        # scores = e.masked_fill(mask == 0, -1e9)# b t t 下三角\n",
    "        a = self.softmax(e) #B*T\n",
    "        v = torch.matmul(a.unsqueeze(1), input).squeeze() #B*I\n",
    "\n",
    "        return v, a\n",
    "\n",
    "class FinalAttentionQKV(nn.Module):\n",
    "    def __init__(self, attention_input_dim, attention_hidden_dim, attention_type='add', dropout=None):\n",
    "        super(FinalAttentionQKV, self).__init__()\n",
    "        \n",
    "        self.attention_type = attention_type\n",
    "        self.attention_hidden_dim = attention_hidden_dim\n",
    "        self.attention_input_dim = attention_input_dim\n",
    "\n",
    "\n",
    "        self.W_q = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
    "        self.W_k = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
    "        self.W_v = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
    "\n",
    "        self.W_out = nn.Linear(attention_hidden_dim, 1)\n",
    "\n",
    "        self.b_in = nn.Parameter(torch.zeros(1,))\n",
    "        self.b_out = nn.Parameter(torch.zeros(1,))\n",
    "\n",
    "        nn.init.kaiming_uniform_(self.W_q.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.W_k.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.W_v.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.W_out.weight, a=math.sqrt(5))\n",
    "\n",
    "        self.Wh = nn.Parameter(torch.randn(2*attention_input_dim, attention_hidden_dim))\n",
    "        self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
    "        self.ba = nn.Parameter(torch.zeros(1,))\n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.Wh, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, input):\n",
    " \n",
    "        batch_size, time_step, input_dim = input.size() # batch_size * input_dim + 1 * hidden_dim(i)\n",
    "        input_q = self.W_q(input[:, -1, :]) # b h\n",
    "        input_k = self.W_k(input)# b t h\n",
    "        input_v = self.W_v(input)# b t h\n",
    "\n",
    "        if self.attention_type == 'add': #B*T*I  @ H*I\n",
    "\n",
    "            q = torch.reshape(input_q, (batch_size, 1, self.attention_hidden_dim)) #B*1*H\n",
    "            h = q + input_k + self.b_in # b t h\n",
    "            h = self.tanh(h) #B*T*H\n",
    "            e = self.W_out(h) # b t 1\n",
    "            e = torch.reshape(e, (batch_size, time_step))# b t\n",
    "\n",
    "        elif self.attention_type == 'mul':\n",
    "            q = torch.reshape(input_q, (batch_size, self.attention_hidden_dim, 1)) #B*h 1\n",
    "            e = torch.matmul(input_k, q).squeeze()#b t\n",
    "            \n",
    "        elif self.attention_type == 'concat':\n",
    "            q = input_q.unsqueeze(1).repeat(1,time_step,1)# b t h\n",
    "            k = input_k\n",
    "            c = torch.cat((q, k), dim=-1) #B*T*2I\n",
    "            h = torch.matmul(c, self.Wh)\n",
    "            h = self.tanh(h)\n",
    "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
    "            e = torch.reshape(e, (batch_size, time_step)) # b t \n",
    "        \n",
    "        a = self.softmax(e) #B*T\n",
    "        if self.dropout is not None:\n",
    "            a = self.dropout(a)\n",
    "        v = torch.matmul(a.unsqueeze(1), input_v).squeeze() #B*I\n",
    "\n",
    "        return v, a\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "def tile(a, dim, n_tile):\n",
    "    init_dim = a.size(dim)\n",
    "    repeat_idx = [1] * a.dim()\n",
    "    repeat_idx[dim] = n_tile\n",
    "    a = a.repeat(*(repeat_idx))\n",
    "    order_index = torch.LongTensor(np.concatenate([init_dim * np.arange(n_tile) + i for i in range(init_dim)])).to(device)\n",
    "    return torch.index_select(a, dim, order_index).to(device)\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module): # new added\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x)))), None\n",
    "\n",
    "# class PositionwiseFeedForwardConv(nn.Module):\n",
    "\n",
    "#     def __init__(self, model_dim=512, ffn_dim=2048, dropout=0.0):\n",
    "#         super(PositionalWiseFeedForward, self).__init__()\n",
    "#         self.w1 = nn.Conv1d(model_dim, ffn_dim, 1)\n",
    "#         self.w2 = nn.Conv1d(model_dim, ffn_dim, 1)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.layer_norm = nn.LayerNorm(model_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         output = x.transpose(1, 2)\n",
    "#         output = self.w2(F.relu(self.w1(output)))\n",
    "#         output = self.dropout(output.transpose(1, 2))\n",
    "\n",
    "#         # add residual and norm layer\n",
    "#         output = self.layer_norm(x + output)\n",
    "#         return output\n",
    "\n",
    "class PositionalEncoding(nn.Module): # new added / not use anymore\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=400):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0., max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0., d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0 # 下三角矩阵\n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)# b h t d_k\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k) # b h t t\n",
    "    if mask is not None:# 1 1 t t\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)# b h t t 下三角\n",
    "    p_attn = F.softmax(scores, dim = -1)# b h t t\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn # b h t v (d_k) \n",
    "    \n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, self.d_k * self.h), 3)\n",
    "        self.final_linear = nn.Linear(d_model, d_model)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1) # 1 1 t t\n",
    "\n",
    "        nbatches = query.size(0)# b\n",
    "        input_dim = query.size(1)# i+1\n",
    "        feature_dim = query.size(-1)# i+1\n",
    "\n",
    "        #input size -> # batch_size * d_input * hidden_dim\n",
    "        \n",
    "        # d_model => h * d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))] # b num_head d_input d_k\n",
    "        \n",
    "       \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)# b num_head d_input d_v (d_k) \n",
    "\n",
    "      \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)# batch_size * d_input * hidden_dim\n",
    "\n",
    "        #DeCov \n",
    "        DeCov_contexts = x.transpose(0, 1).transpose(1, 2) # I+1 H B\n",
    "        Covs = cov(DeCov_contexts[0,:,:])\n",
    "        DeCov_loss = 0.5 * (torch.norm(Covs, p = 'fro')**2 - torch.norm(torch.diag(Covs))**2 ) \n",
    "        for i in range(feature_dim -1 + 1):\n",
    "            Covs = cov(DeCov_contexts[i+1,:,:])\n",
    "            DeCov_loss += 0.5 * (torch.norm(Covs, p = 'fro')**2 - torch.norm(torch.diag(Covs))**2 ) \n",
    "\n",
    "\n",
    "        return self.final_linear(x), DeCov_loss\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps=1e-7):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "\n",
    "def cov(m, y=None):\n",
    "    if y is not None:\n",
    "        m = torch.cat((m, y), dim=0)\n",
    "    m_exp = torch.mean(m, dim=1)\n",
    "    x = m - m_exp[:, None]\n",
    "    cov = 1 / (x.size(1) - 1) * x.mm(x.t())\n",
    "    return cov\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        returned_value = sublayer(self.norm(x))\n",
    "        return x + self.dropout(returned_value[0]) , returned_value[1]\n",
    "\n",
    "class ConCare(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, d_model,  MHD_num_head, d_ff, output_dim, keep_prob=0.5):\n",
    "        super(ConCare, self).__init__()\n",
    "\n",
    "        # hyperparameters\n",
    "        self.input_dim = input_dim  \n",
    "        self.hidden_dim = hidden_dim  # d_model\n",
    "        self.d_model = d_model\n",
    "        self.MHD_num_head = MHD_num_head\n",
    "        self.d_ff = d_ff\n",
    "        self.output_dim = output_dim\n",
    "        self.keep_prob = keep_prob\n",
    "\n",
    "        # layers\n",
    "        self.PositionalEncoding = PositionalEncoding(self.d_model, dropout = 0, max_len = 400)\n",
    "\n",
    "        self.GRUs = clones(nn.GRU(1, self.hidden_dim, batch_first = True), self.input_dim)\n",
    "        self.LastStepAttentions = clones(SingleAttention(self.hidden_dim, 8, attention_type='new', demographic_dim=12, time_aware=True, use_demographic=False),self.input_dim)\n",
    "        \n",
    "        self.FinalAttentionQKV = FinalAttentionQKV(self.hidden_dim, self.hidden_dim, attention_type='mul',dropout = 1 - self.keep_prob)\n",
    "\n",
    "        self.MultiHeadedAttention = MultiHeadedAttention(self.MHD_num_head, self.d_model,dropout = 1 - self.keep_prob)\n",
    "        self.SublayerConnection = SublayerConnection(self.d_model, dropout = 1 - self.keep_prob)\n",
    "\n",
    "        self.PositionwiseFeedForward = PositionwiseFeedForward(self.d_model, self.d_ff, dropout=0.1)\n",
    "\n",
    "        self.demo_proj_main = nn.Linear(12, self.hidden_dim)\n",
    "        self.demo_proj = nn.Linear(12, self.hidden_dim)\n",
    "        self.output0 = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.output1 = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(p = 1 - self.keep_prob)\n",
    "        self.tanh=nn.Tanh()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    def forward(self, input, demo_input):\n",
    "        # input shape [batch_size, timestep, feature_dim]\n",
    "        demo_main = self.tanh(self.demo_proj_main(demo_input)).unsqueeze(1)# b hidden_dim\n",
    "        \n",
    "        batch_size = input.size(0)\n",
    "        time_step = input.size(1)\n",
    "        feature_dim = input.size(2)\n",
    "        assert(feature_dim == self.input_dim)# input Tensor : 256 * 48 * 76\n",
    "        assert(self.d_model % self.MHD_num_head == 0)\n",
    "\n",
    "        # Initialization\n",
    "        #cur_hs = Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0))\n",
    "\n",
    "        # forward\n",
    "        GRU_embeded_input = self.GRUs[0](input[:,:,0].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0)).to(device))[0] # b t h\n",
    "        Attention_embeded_input = self.LastStepAttentions[0](GRU_embeded_input)[0].unsqueeze(1)# b 1 h\n",
    "        for i in range(feature_dim-1):\n",
    "            embeded_input = self.GRUs[i+1](input[:,:,i+1].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0)).to(device))[0] # b 1 h\n",
    "            embeded_input = self.LastStepAttentions[i+1](embeded_input)[0].unsqueeze(1)# b 1 h\n",
    "            Attention_embeded_input = torch.cat((Attention_embeded_input, embeded_input), 1)# b i h\n",
    "\n",
    "        Attention_embeded_input = torch.cat((Attention_embeded_input, demo_main), 1)# b i+1 h\n",
    "        posi_input = self.dropout(Attention_embeded_input) # batch_size * d_input+1 * hidden_dim\n",
    "\n",
    "#         GRU_embeded_input = self.GRUs[0](input[:,:,0].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0)).to(device))[0][:,-1,:].unsqueeze(1) # b 1 h\n",
    "#         for i in range(feature_dim-1):\n",
    "#             embeded_input = self.GRUs[i+1](input[:,:,i+1].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0)).to(device))[0][:,-1,:].unsqueeze(1) # b 1 h\n",
    "#             GRU_embeded_input = torch.cat((GRU_embeded_input, embeded_input), 1)\n",
    "\n",
    "#         GRU_embeded_input = torch.cat((GRU_embeded_input, demo_main), 1)# b i+1 h\n",
    "#         posi_input = self.dropout(GRU_embeded_input) # batch_size * d_input * hidden_dim\n",
    "\n",
    "\n",
    "        #mask = subsequent_mask(time_step).to(device) # 1 t t 下三角 N to 1任务不用mask\n",
    "        contexts = self.SublayerConnection(posi_input, lambda x: self.MultiHeadedAttention(posi_input, posi_input, posi_input, None))# # batch_size * d_input * hidden_dim\n",
    "    \n",
    "        DeCov_loss = contexts[1]\n",
    "        contexts = contexts[0]\n",
    "\n",
    "        contexts = self.SublayerConnection(contexts, lambda x: self.PositionwiseFeedForward(contexts))[0]# # batch_size * d_input * hidden_dim\n",
    "        #contexts = contexts.view(batch_size, feature_dim * self.hidden_dim)#\n",
    "        # contexts = torch.matmul(self.Wproj, contexts) + self.bproj\n",
    "        # contexts = contexts.squeeze()\n",
    "        # demo_key = self.demo_proj(demo_input)# b hidden_dim\n",
    "        # demo_key = self.relu(demo_key)\n",
    "        # input_dim_scores = torch.matmul(contexts, demo_key.unsqueeze(-1)).squeeze() # b i\n",
    "        # input_dim_scores = self.dropout(self.sigmoid(input_dim_scores)).unsqueeze(1)# b i\n",
    "        \n",
    "        # weighted_contexts = torch.matmul(input_dim_scores, contexts).squeeze()\n",
    "\n",
    "        weighted_contexts = self.FinalAttentionQKV(contexts)[0]\n",
    "        output = self.output1(self.relu(self.output0(weighted_contexts)))# b 1\n",
    "        output = self.sigmoid(output)\n",
    "          \n",
    "        return output, DeCov_loss\n",
    "    #, self.MultiHeadedAttention.attn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T02:12:48.282265Z",
     "start_time": "2021-11-02T02:12:48.191901Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_loss(y_pred, y_true):\n",
    "    loss = torch.nn.BCELoss()\n",
    "    return loss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T02:12:48.355893Z",
     "start_time": "2021-11-02T02:12:48.284802Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, x, y, name):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.name = name\n",
    "\n",
    "    def __getitem__(self, index):#返回的是tensor\n",
    "        return self.x[index], self.y[index], self.name[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T02:12:48.442051Z",
     "start_time": "2021-11-02T02:12:48.358759Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_raw['data'][0], train_raw['data'][1], train_raw['names'])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataset = Dataset(val_raw['data'][0], val_raw['data'][1], val_raw['names'])\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T03:27:01.575443Z",
     "start_time": "2021-11-02T02:12:48.445259Z"
    },
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED) #numpy\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED) # cpu\n",
    "torch.cuda.manual_seed(RANDOM_SEED) #gpu\n",
    "torch.backends.cudnn.deterministic=True # cudnn\n",
    "\n",
    "model = ConCare(input_dim = 76, hidden_dim = 64, d_model = 64,  MHD_num_head = 4 , d_ff = 256, output_dim = 1).to(device)\n",
    "# input_dim, d_model, d_k, d_v, MHD_num_head, d_ff, output_dim\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "max_roc = 0\n",
    "max_prc = 0\n",
    "train_loss = []\n",
    "train_model_loss = []\n",
    "train_decov_loss = []\n",
    "valid_loss = []\n",
    "valid_model_loss = []\n",
    "valid_decov_loss = []\n",
    "history = []\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "np.set_printoptions(precision=2)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "for each_epoch in range(100):\n",
    "    batch_loss = []\n",
    "    model_batch_loss = []\n",
    "    decov_batch_loss = []\n",
    "\n",
    "    model.train()\n",
    " \n",
    "    for step, (batch_x, batch_y, batch_name) in enumerate(train_loader):   \n",
    "        optimizer.zero_grad()\n",
    "        batch_x = batch_x.float().to(device)\n",
    "        batch_y = batch_y.float().to(device)\n",
    "\n",
    "        batch_demo = []\n",
    "        for i in range(len(batch_name)):\n",
    "            cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n",
    "            cur_idx = cur_id + '_' + cur_ep\n",
    "            cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n",
    "            batch_demo.append(cur_demo)\n",
    "        \n",
    "        batch_demo = torch.stack(batch_demo).to(device)\n",
    "        output, decov_loss = model(batch_x, batch_demo)\n",
    "        \n",
    "        \n",
    "        model_loss = get_loss(output, batch_y.unsqueeze(-1))\n",
    "        loss = model_loss + 800* decov_loss\n",
    "        \n",
    "        batch_loss.append(loss.cpu().detach().numpy())\n",
    "        model_batch_loss.append(model_loss.cpu().detach().numpy())\n",
    "        decov_batch_loss.append(decov_loss.cpu().detach().numpy())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 30 == 0:\n",
    "            print('Epoch %d Batch %d: Train Loss = %.4f'%(each_epoch, step, np.mean(np.array(batch_loss))))\n",
    "            print('Model Loss = %.4f, Decov Loss = %.4f'%(np.mean(np.array(model_batch_loss)), np.mean(np.array(decov_batch_loss))))\n",
    "    train_loss.append(np.mean(np.array(batch_loss)))\n",
    "    train_model_loss.append(np.mean(np.array(model_batch_loss)))\n",
    "    train_decov_loss.append(np.mean(np.array(decov_batch_loss)))\n",
    "    \n",
    "    batch_loss = []\n",
    "    model_batch_loss = []\n",
    "    decov_batch_loss = []\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for step, (batch_x, batch_y, batch_name) in enumerate(valid_loader):\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "            batch_demo = []\n",
    "            for i in range(len(batch_name)):\n",
    "                cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n",
    "                cur_idx = cur_id + '_' + cur_ep\n",
    "                cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n",
    "                batch_demo.append(cur_demo)\n",
    "\n",
    "            batch_demo = torch.stack(batch_demo).to(device)\n",
    "            output,decov_loss = model(batch_x, batch_demo)\n",
    "            \n",
    "            model_loss = get_loss(output, batch_y.unsqueeze(-1))\n",
    "\n",
    "            loss = model_loss + 10* decov_loss\n",
    "            batch_loss.append(loss.cpu().detach().numpy())\n",
    "            model_batch_loss.append(model_loss.cpu().detach().numpy())\n",
    "            decov_batch_loss.append(decov_loss.cpu().detach().numpy())\n",
    "            y_pred += list(output.cpu().detach().numpy().flatten())\n",
    "            y_true += list(batch_y.cpu().numpy().flatten())\n",
    "            \n",
    "    valid_loss.append(np.mean(np.array(batch_loss)))\n",
    "    valid_model_loss.append(np.mean(np.array(model_batch_loss)))\n",
    "    valid_decov_loss.append(np.mean(np.array(decov_batch_loss)))\n",
    "    \n",
    "    print(\"\\n==>Predicting on validation\")\n",
    "    print('Valid Loss = %.4f'%(valid_loss[-1]))\n",
    "    print('valid_model Loss = %.4f'%(valid_model_loss[-1]))\n",
    "    print('valid_decov Loss = %.4f'%(valid_decov_loss[-1]))\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n",
    "    ret = metrics.print_metrics_binary(y_true, y_pred)\n",
    "    history.append(ret)\n",
    "    print()\n",
    "\n",
    "    cur_auroc = ret['auroc']\n",
    "    \n",
    "    if cur_auroc > max_roc:\n",
    "        max_roc = cur_auroc\n",
    "        state = {\n",
    "            'net': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': each_epoch\n",
    "        }\n",
    "        torch.save(state, file_name)\n",
    "        print('\\n------------ Save best model ------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T03:27:16.741911Z",
     "start_time": "2021-11-02T03:27:01.578022Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(file_name)\n",
    "save_epoch = checkpoint['epoch']\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "model.eval()\n",
    "\n",
    "test_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data_path, 'test'),\n",
    "                                            listfile=os.path.join(data_path, 'test_listfile.csv'),\n",
    "                                            period_length=48.0)\n",
    "test_raw = utils.load_data(test_reader, discretizer, normalizer, small_part, return_names=True)\n",
    "test_dataset = Dataset(test_raw['data'][0], test_raw['data'][1], test_raw['names'])\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T03:27:20.964397Z",
     "start_time": "2021-11-02T03:27:16.745558Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==>Predicting on test\n",
      "Test Loss = 0.2532\n",
      "confusion matrix:\n",
      "[[2811   51]\n",
      " [ 270  104]]\n",
      "accuracy = 0.9008034467697144\n",
      "precision class 0 = 0.9123660922050476\n",
      "precision class 1 = 0.6709677577018738\n",
      "recall class 0 = 0.9821802973747253\n",
      "recall class 1 = 0.27807486057281494\n",
      "AUC of ROC = 0.8719613822277529\n",
      "AUC of PRC = 0.5344983146118463\n",
      "min(+P, Se) = 0.5106951871657754\n",
      "f1_score = 0.3931947039659704\n"
     ]
    }
   ],
   "source": [
    "batch_loss = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for step, (batch_x, batch_y, batch_name) in enumerate(test_loader):\n",
    "        batch_x = batch_x.float().to(device)\n",
    "        batch_y = batch_y.float().to(device)\n",
    "        batch_demo = []\n",
    "        for i in range(len(batch_name)):\n",
    "            cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n",
    "            cur_idx = cur_id + '_' + cur_ep\n",
    "            cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n",
    "            batch_demo.append(cur_demo)\n",
    "\n",
    "        batch_demo = torch.stack(batch_demo).to(device)\n",
    "        output = model(batch_x, batch_demo)[0]\n",
    "\n",
    "        loss = get_loss(output, batch_y.unsqueeze(-1))\n",
    "        batch_loss.append(loss.cpu().detach().numpy())\n",
    "        y_pred += list(output.cpu().detach().numpy().flatten())\n",
    "        y_true += list(batch_y.cpu().numpy().flatten())\n",
    "\n",
    "print(\"\\n==>Predicting on test\")\n",
    "print('Test Loss = %.4f'%(np.mean(np.array(batch_loss))))\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n",
    "test_res = metrics.print_metrics_binary(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T03:27:35.542743Z",
     "start_time": "2021-11-02T03:27:20.967136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1000\n",
      "2/1000\n",
      "3/1000\n",
      "4/1000\n",
      "5/1000\n",
      "6/1000\n",
      "7/1000\n",
      "8/1000\n",
      "9/1000\n",
      "10/1000\n",
      "11/1000\n",
      "12/1000\n",
      "13/1000\n",
      "14/1000\n",
      "15/1000\n",
      "16/1000\n",
      "17/1000\n",
      "18/1000\n",
      "19/1000\n",
      "20/1000\n",
      "21/1000\n",
      "22/1000\n",
      "23/1000\n",
      "24/1000\n",
      "25/1000\n",
      "26/1000\n",
      "27/1000\n",
      "28/1000\n",
      "29/1000\n",
      "30/1000\n",
      "31/1000\n",
      "32/1000\n",
      "33/1000\n",
      "34/1000\n",
      "35/1000\n",
      "36/1000\n",
      "37/1000\n",
      "38/1000\n",
      "39/1000\n",
      "40/1000\n",
      "41/1000\n",
      "42/1000\n",
      "43/1000\n",
      "44/1000\n",
      "45/1000\n",
      "46/1000\n",
      "47/1000\n",
      "48/1000\n",
      "49/1000\n",
      "50/1000\n",
      "51/1000\n",
      "52/1000\n",
      "53/1000\n",
      "54/1000\n",
      "55/1000\n",
      "56/1000\n",
      "57/1000\n",
      "58/1000\n",
      "59/1000\n",
      "60/1000\n",
      "61/1000\n",
      "62/1000\n",
      "63/1000\n",
      "64/1000\n",
      "65/1000\n",
      "66/1000\n",
      "67/1000\n",
      "68/1000\n",
      "69/1000\n",
      "70/1000\n",
      "71/1000\n",
      "72/1000\n",
      "73/1000\n",
      "74/1000\n",
      "75/1000\n",
      "76/1000\n",
      "77/1000\n",
      "78/1000\n",
      "79/1000\n",
      "80/1000\n",
      "81/1000\n",
      "82/1000\n",
      "83/1000\n",
      "84/1000\n",
      "85/1000\n",
      "86/1000\n",
      "87/1000\n",
      "88/1000\n",
      "89/1000\n",
      "90/1000\n",
      "91/1000\n",
      "92/1000\n",
      "93/1000\n",
      "94/1000\n",
      "95/1000\n",
      "96/1000\n",
      "97/1000\n",
      "98/1000\n",
      "99/1000\n",
      "100/1000\n",
      "101/1000\n",
      "102/1000\n",
      "103/1000\n",
      "104/1000\n",
      "105/1000\n",
      "106/1000\n",
      "107/1000\n",
      "108/1000\n",
      "109/1000\n",
      "110/1000\n",
      "111/1000\n",
      "112/1000\n",
      "113/1000\n",
      "114/1000\n",
      "115/1000\n",
      "116/1000\n",
      "117/1000\n",
      "118/1000\n",
      "119/1000\n",
      "120/1000\n",
      "121/1000\n",
      "122/1000\n",
      "123/1000\n",
      "124/1000\n",
      "125/1000\n",
      "126/1000\n",
      "127/1000\n",
      "128/1000\n",
      "129/1000\n",
      "130/1000\n",
      "131/1000\n",
      "132/1000\n",
      "133/1000\n",
      "134/1000\n",
      "135/1000\n",
      "136/1000\n",
      "137/1000\n",
      "138/1000\n",
      "139/1000\n",
      "140/1000\n",
      "141/1000\n",
      "142/1000\n",
      "143/1000\n",
      "144/1000\n",
      "145/1000\n",
      "146/1000\n",
      "147/1000\n",
      "148/1000\n",
      "149/1000\n",
      "150/1000\n",
      "151/1000\n",
      "152/1000\n",
      "153/1000\n",
      "154/1000\n",
      "155/1000\n",
      "156/1000\n",
      "157/1000\n",
      "158/1000\n",
      "159/1000\n",
      "160/1000\n",
      "161/1000\n",
      "162/1000\n",
      "163/1000\n",
      "164/1000\n",
      "165/1000\n",
      "166/1000\n",
      "167/1000\n",
      "168/1000\n",
      "169/1000\n",
      "170/1000\n",
      "171/1000\n",
      "172/1000\n",
      "173/1000\n",
      "174/1000\n",
      "175/1000\n",
      "176/1000\n",
      "177/1000\n",
      "178/1000\n",
      "179/1000\n",
      "180/1000\n",
      "181/1000\n",
      "182/1000\n",
      "183/1000\n",
      "184/1000\n",
      "185/1000\n",
      "186/1000\n",
      "187/1000\n",
      "188/1000\n",
      "189/1000\n",
      "190/1000\n",
      "191/1000\n",
      "192/1000\n",
      "193/1000\n",
      "194/1000\n",
      "195/1000\n",
      "196/1000\n",
      "197/1000\n",
      "198/1000\n",
      "199/1000\n",
      "200/1000\n",
      "201/1000\n",
      "202/1000\n",
      "203/1000\n",
      "204/1000\n",
      "205/1000\n",
      "206/1000\n",
      "207/1000\n",
      "208/1000\n",
      "209/1000\n",
      "210/1000\n",
      "211/1000\n",
      "212/1000\n",
      "213/1000\n",
      "214/1000\n",
      "215/1000\n",
      "216/1000\n",
      "217/1000\n",
      "218/1000\n",
      "219/1000\n",
      "220/1000\n",
      "221/1000\n",
      "222/1000\n",
      "223/1000\n",
      "224/1000\n",
      "225/1000\n",
      "226/1000\n",
      "227/1000\n",
      "228/1000\n",
      "229/1000\n",
      "230/1000\n",
      "231/1000\n",
      "232/1000\n",
      "233/1000\n",
      "234/1000\n",
      "235/1000\n",
      "236/1000\n",
      "237/1000\n",
      "238/1000\n",
      "239/1000\n",
      "240/1000\n",
      "241/1000\n",
      "242/1000\n",
      "243/1000\n",
      "244/1000\n",
      "245/1000\n",
      "246/1000\n",
      "247/1000\n",
      "248/1000\n",
      "249/1000\n",
      "250/1000\n",
      "251/1000\n",
      "252/1000\n",
      "253/1000\n",
      "254/1000\n",
      "255/1000\n",
      "256/1000\n",
      "257/1000\n",
      "258/1000\n",
      "259/1000\n",
      "260/1000\n",
      "261/1000\n",
      "262/1000\n",
      "263/1000\n",
      "264/1000\n",
      "265/1000\n",
      "266/1000\n",
      "267/1000\n",
      "268/1000\n",
      "269/1000\n",
      "270/1000\n",
      "271/1000\n",
      "272/1000\n",
      "273/1000\n",
      "274/1000\n",
      "275/1000\n",
      "276/1000\n",
      "277/1000\n",
      "278/1000\n",
      "279/1000\n",
      "280/1000\n",
      "281/1000\n",
      "282/1000\n",
      "283/1000\n",
      "284/1000\n",
      "285/1000\n",
      "286/1000\n",
      "287/1000\n",
      "288/1000\n",
      "289/1000\n",
      "290/1000\n",
      "291/1000\n",
      "292/1000\n",
      "293/1000\n",
      "294/1000\n",
      "295/1000\n",
      "296/1000\n",
      "297/1000\n",
      "298/1000\n",
      "299/1000\n",
      "300/1000\n",
      "301/1000\n",
      "302/1000\n",
      "303/1000\n",
      "304/1000\n",
      "305/1000\n",
      "306/1000\n",
      "307/1000\n",
      "308/1000\n",
      "309/1000\n",
      "310/1000\n",
      "311/1000\n",
      "312/1000\n",
      "313/1000\n",
      "314/1000\n",
      "315/1000\n",
      "316/1000\n",
      "317/1000\n",
      "318/1000\n",
      "319/1000\n",
      "320/1000\n",
      "321/1000\n",
      "322/1000\n",
      "323/1000\n",
      "324/1000\n",
      "325/1000\n",
      "326/1000\n",
      "327/1000\n",
      "328/1000\n",
      "329/1000\n",
      "330/1000\n",
      "331/1000\n",
      "332/1000\n",
      "333/1000\n",
      "334/1000\n",
      "335/1000\n",
      "336/1000\n",
      "337/1000\n",
      "338/1000\n",
      "339/1000\n",
      "340/1000\n",
      "341/1000\n",
      "342/1000\n",
      "343/1000\n",
      "344/1000\n",
      "345/1000\n",
      "346/1000\n",
      "347/1000\n",
      "348/1000\n",
      "349/1000\n",
      "350/1000\n",
      "351/1000\n",
      "352/1000\n",
      "353/1000\n",
      "354/1000\n",
      "355/1000\n",
      "356/1000\n",
      "357/1000\n",
      "358/1000\n",
      "359/1000\n",
      "360/1000\n",
      "361/1000\n",
      "362/1000\n",
      "363/1000\n",
      "364/1000\n",
      "365/1000\n",
      "366/1000\n",
      "367/1000\n",
      "368/1000\n",
      "369/1000\n",
      "370/1000\n",
      "371/1000\n",
      "372/1000\n",
      "373/1000\n",
      "374/1000\n",
      "375/1000\n",
      "376/1000\n",
      "377/1000\n",
      "378/1000\n",
      "379/1000\n",
      "380/1000\n",
      "381/1000\n",
      "382/1000\n",
      "383/1000\n",
      "384/1000\n",
      "385/1000\n",
      "386/1000\n",
      "387/1000\n",
      "388/1000\n",
      "389/1000\n",
      "390/1000\n",
      "391/1000\n",
      "392/1000\n",
      "393/1000\n",
      "394/1000\n",
      "395/1000\n",
      "396/1000\n",
      "397/1000\n",
      "398/1000\n",
      "399/1000\n",
      "400/1000\n",
      "401/1000\n",
      "402/1000\n",
      "403/1000\n",
      "404/1000\n",
      "405/1000\n",
      "406/1000\n",
      "407/1000\n",
      "408/1000\n",
      "409/1000\n",
      "410/1000\n",
      "411/1000\n",
      "412/1000\n",
      "413/1000\n",
      "414/1000\n",
      "415/1000\n",
      "416/1000\n",
      "417/1000\n",
      "418/1000\n",
      "419/1000\n",
      "420/1000\n",
      "421/1000\n",
      "422/1000\n",
      "423/1000\n",
      "424/1000\n",
      "425/1000\n",
      "426/1000\n",
      "427/1000\n",
      "428/1000\n",
      "429/1000\n",
      "430/1000\n",
      "431/1000\n",
      "432/1000\n",
      "433/1000\n",
      "434/1000\n",
      "435/1000\n",
      "436/1000\n",
      "437/1000\n",
      "438/1000\n",
      "439/1000\n",
      "440/1000\n",
      "441/1000\n",
      "442/1000\n",
      "443/1000\n",
      "444/1000\n",
      "445/1000\n",
      "446/1000\n",
      "447/1000\n",
      "448/1000\n",
      "449/1000\n",
      "450/1000\n",
      "451/1000\n",
      "452/1000\n",
      "453/1000\n",
      "454/1000\n",
      "455/1000\n",
      "456/1000\n",
      "457/1000\n",
      "458/1000\n",
      "459/1000\n",
      "460/1000\n",
      "461/1000\n",
      "462/1000\n",
      "463/1000\n",
      "464/1000\n",
      "465/1000\n",
      "466/1000\n",
      "467/1000\n",
      "468/1000\n",
      "469/1000\n",
      "470/1000\n",
      "471/1000\n",
      "472/1000\n",
      "473/1000\n",
      "474/1000\n",
      "475/1000\n",
      "476/1000\n",
      "477/1000\n",
      "478/1000\n",
      "479/1000\n",
      "480/1000\n",
      "481/1000\n",
      "482/1000\n",
      "483/1000\n",
      "484/1000\n",
      "485/1000\n",
      "486/1000\n",
      "487/1000\n",
      "488/1000\n",
      "489/1000\n",
      "490/1000\n",
      "491/1000\n",
      "492/1000\n",
      "493/1000\n",
      "494/1000\n",
      "495/1000\n",
      "496/1000\n",
      "497/1000\n",
      "498/1000\n",
      "499/1000\n",
      "500/1000\n",
      "501/1000\n",
      "502/1000\n",
      "503/1000\n",
      "504/1000\n",
      "505/1000\n",
      "506/1000\n",
      "507/1000\n",
      "508/1000\n",
      "509/1000\n",
      "510/1000\n",
      "511/1000\n",
      "512/1000\n",
      "513/1000\n",
      "514/1000\n",
      "515/1000\n",
      "516/1000\n",
      "517/1000\n",
      "518/1000\n",
      "519/1000\n",
      "520/1000\n",
      "521/1000\n",
      "522/1000\n",
      "523/1000\n",
      "524/1000\n",
      "525/1000\n",
      "526/1000\n",
      "527/1000\n",
      "528/1000\n",
      "529/1000\n",
      "530/1000\n",
      "531/1000\n",
      "532/1000\n",
      "533/1000\n",
      "534/1000\n",
      "535/1000\n",
      "536/1000\n",
      "537/1000\n",
      "538/1000\n",
      "539/1000\n",
      "540/1000\n",
      "541/1000\n",
      "542/1000\n",
      "543/1000\n",
      "544/1000\n",
      "545/1000\n",
      "546/1000\n",
      "547/1000\n",
      "548/1000\n",
      "549/1000\n",
      "550/1000\n",
      "551/1000\n",
      "552/1000\n",
      "553/1000\n",
      "554/1000\n",
      "555/1000\n",
      "556/1000\n",
      "557/1000\n",
      "558/1000\n",
      "559/1000\n",
      "560/1000\n",
      "561/1000\n",
      "562/1000\n",
      "563/1000\n",
      "564/1000\n",
      "565/1000\n",
      "566/1000\n",
      "567/1000\n",
      "568/1000\n",
      "569/1000\n",
      "570/1000\n",
      "571/1000\n",
      "572/1000\n",
      "573/1000\n",
      "574/1000\n",
      "575/1000\n",
      "576/1000\n",
      "577/1000\n",
      "578/1000\n",
      "579/1000\n",
      "580/1000\n",
      "581/1000\n",
      "582/1000\n",
      "583/1000\n",
      "584/1000\n",
      "585/1000\n",
      "586/1000\n",
      "587/1000\n",
      "588/1000\n",
      "589/1000\n",
      "590/1000\n",
      "591/1000\n",
      "592/1000\n",
      "593/1000\n",
      "594/1000\n",
      "595/1000\n",
      "596/1000\n",
      "597/1000\n",
      "598/1000\n",
      "599/1000\n",
      "600/1000\n",
      "601/1000\n",
      "602/1000\n",
      "603/1000\n",
      "604/1000\n",
      "605/1000\n",
      "606/1000\n",
      "607/1000\n",
      "608/1000\n",
      "609/1000\n",
      "610/1000\n",
      "611/1000\n",
      "612/1000\n",
      "613/1000\n",
      "614/1000\n",
      "615/1000\n",
      "616/1000\n",
      "617/1000\n",
      "618/1000\n",
      "619/1000\n",
      "620/1000\n",
      "621/1000\n",
      "622/1000\n",
      "623/1000\n",
      "624/1000\n",
      "625/1000\n",
      "626/1000\n",
      "627/1000\n",
      "628/1000\n",
      "629/1000\n",
      "630/1000\n",
      "631/1000\n",
      "632/1000\n",
      "633/1000\n",
      "634/1000\n",
      "635/1000\n",
      "636/1000\n",
      "637/1000\n",
      "638/1000\n",
      "639/1000\n",
      "640/1000\n",
      "641/1000\n",
      "642/1000\n",
      "643/1000\n",
      "644/1000\n",
      "645/1000\n",
      "646/1000\n",
      "647/1000\n",
      "648/1000\n",
      "649/1000\n",
      "650/1000\n",
      "651/1000\n",
      "652/1000\n",
      "653/1000\n",
      "654/1000\n",
      "655/1000\n",
      "656/1000\n",
      "657/1000\n",
      "658/1000\n",
      "659/1000\n",
      "660/1000\n",
      "661/1000\n",
      "662/1000\n",
      "663/1000\n",
      "664/1000\n",
      "665/1000\n",
      "666/1000\n",
      "667/1000\n",
      "668/1000\n",
      "669/1000\n",
      "670/1000\n",
      "671/1000\n",
      "672/1000\n",
      "673/1000\n",
      "674/1000\n",
      "675/1000\n",
      "676/1000\n",
      "677/1000\n",
      "678/1000\n",
      "679/1000\n",
      "680/1000\n",
      "681/1000\n",
      "682/1000\n",
      "683/1000\n",
      "684/1000\n",
      "685/1000\n",
      "686/1000\n",
      "687/1000\n",
      "688/1000\n",
      "689/1000\n",
      "690/1000\n",
      "691/1000\n",
      "692/1000\n",
      "693/1000\n",
      "694/1000\n",
      "695/1000\n",
      "696/1000\n",
      "697/1000\n",
      "698/1000\n",
      "699/1000\n",
      "700/1000\n",
      "701/1000\n",
      "702/1000\n",
      "703/1000\n",
      "704/1000\n",
      "705/1000\n",
      "706/1000\n",
      "707/1000\n",
      "708/1000\n",
      "709/1000\n",
      "710/1000\n",
      "711/1000\n",
      "712/1000\n",
      "713/1000\n",
      "714/1000\n",
      "715/1000\n",
      "716/1000\n",
      "717/1000\n",
      "718/1000\n",
      "719/1000\n",
      "720/1000\n",
      "721/1000\n",
      "722/1000\n",
      "723/1000\n",
      "724/1000\n",
      "725/1000\n",
      "726/1000\n",
      "727/1000\n",
      "728/1000\n",
      "729/1000\n",
      "730/1000\n",
      "731/1000\n",
      "732/1000\n",
      "733/1000\n",
      "734/1000\n",
      "735/1000\n",
      "736/1000\n",
      "737/1000\n",
      "738/1000\n",
      "739/1000\n",
      "740/1000\n",
      "741/1000\n",
      "742/1000\n",
      "743/1000\n",
      "744/1000\n",
      "745/1000\n",
      "746/1000\n",
      "747/1000\n",
      "748/1000\n",
      "749/1000\n",
      "750/1000\n",
      "751/1000\n",
      "752/1000\n",
      "753/1000\n",
      "754/1000\n",
      "755/1000\n",
      "756/1000\n",
      "757/1000\n",
      "758/1000\n",
      "759/1000\n",
      "760/1000\n",
      "761/1000\n",
      "762/1000\n",
      "763/1000\n",
      "764/1000\n",
      "765/1000\n",
      "766/1000\n",
      "767/1000\n",
      "768/1000\n",
      "769/1000\n",
      "770/1000\n",
      "771/1000\n",
      "772/1000\n",
      "773/1000\n",
      "774/1000\n",
      "775/1000\n",
      "776/1000\n",
      "777/1000\n",
      "778/1000\n",
      "779/1000\n",
      "780/1000\n",
      "781/1000\n",
      "782/1000\n",
      "783/1000\n",
      "784/1000\n",
      "785/1000\n",
      "786/1000\n",
      "787/1000\n",
      "788/1000\n",
      "789/1000\n",
      "790/1000\n",
      "791/1000\n",
      "792/1000\n",
      "793/1000\n",
      "794/1000\n",
      "795/1000\n",
      "796/1000\n",
      "797/1000\n",
      "798/1000\n",
      "799/1000\n",
      "800/1000\n",
      "801/1000\n",
      "802/1000\n",
      "803/1000\n",
      "804/1000\n",
      "805/1000\n",
      "806/1000\n",
      "807/1000\n",
      "808/1000\n",
      "809/1000\n",
      "810/1000\n",
      "811/1000\n",
      "812/1000\n",
      "813/1000\n",
      "814/1000\n",
      "815/1000\n",
      "816/1000\n",
      "817/1000\n",
      "818/1000\n",
      "819/1000\n",
      "820/1000\n",
      "821/1000\n",
      "822/1000\n",
      "823/1000\n",
      "824/1000\n",
      "825/1000\n",
      "826/1000\n",
      "827/1000\n",
      "828/1000\n",
      "829/1000\n",
      "830/1000\n",
      "831/1000\n",
      "832/1000\n",
      "833/1000\n",
      "834/1000\n",
      "835/1000\n",
      "836/1000\n",
      "837/1000\n",
      "838/1000\n",
      "839/1000\n",
      "840/1000\n",
      "841/1000\n",
      "842/1000\n",
      "843/1000\n",
      "844/1000\n",
      "845/1000\n",
      "846/1000\n",
      "847/1000\n",
      "848/1000\n",
      "849/1000\n",
      "850/1000\n",
      "851/1000\n",
      "852/1000\n",
      "853/1000\n",
      "854/1000\n",
      "855/1000\n",
      "856/1000\n",
      "857/1000\n",
      "858/1000\n",
      "859/1000\n",
      "860/1000\n",
      "861/1000\n",
      "862/1000\n",
      "863/1000\n",
      "864/1000\n",
      "865/1000\n",
      "866/1000\n",
      "867/1000\n",
      "868/1000\n",
      "869/1000\n",
      "870/1000\n",
      "871/1000\n",
      "872/1000\n",
      "873/1000\n",
      "874/1000\n",
      "875/1000\n",
      "876/1000\n",
      "877/1000\n",
      "878/1000\n",
      "879/1000\n",
      "880/1000\n",
      "881/1000\n",
      "882/1000\n",
      "883/1000\n",
      "884/1000\n",
      "885/1000\n",
      "886/1000\n",
      "887/1000\n",
      "888/1000\n",
      "889/1000\n",
      "890/1000\n",
      "891/1000\n",
      "892/1000\n",
      "893/1000\n",
      "894/1000\n",
      "895/1000\n",
      "896/1000\n",
      "897/1000\n",
      "898/1000\n",
      "899/1000\n",
      "900/1000\n",
      "901/1000\n",
      "902/1000\n",
      "903/1000\n",
      "904/1000\n",
      "905/1000\n",
      "906/1000\n",
      "907/1000\n",
      "908/1000\n",
      "909/1000\n",
      "910/1000\n",
      "911/1000\n",
      "912/1000\n",
      "913/1000\n",
      "914/1000\n",
      "915/1000\n",
      "916/1000\n",
      "917/1000\n",
      "918/1000\n",
      "919/1000\n",
      "920/1000\n",
      "921/1000\n",
      "922/1000\n",
      "923/1000\n",
      "924/1000\n",
      "925/1000\n",
      "926/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927/1000\n",
      "928/1000\n",
      "929/1000\n",
      "930/1000\n",
      "931/1000\n",
      "932/1000\n",
      "933/1000\n",
      "934/1000\n",
      "935/1000\n",
      "936/1000\n",
      "937/1000\n",
      "938/1000\n",
      "939/1000\n",
      "940/1000\n",
      "941/1000\n",
      "942/1000\n",
      "943/1000\n",
      "944/1000\n",
      "945/1000\n",
      "946/1000\n",
      "947/1000\n",
      "948/1000\n",
      "949/1000\n",
      "950/1000\n",
      "951/1000\n",
      "952/1000\n",
      "953/1000\n",
      "954/1000\n",
      "955/1000\n",
      "956/1000\n",
      "957/1000\n",
      "958/1000\n",
      "959/1000\n",
      "960/1000\n",
      "961/1000\n",
      "962/1000\n",
      "963/1000\n",
      "964/1000\n",
      "965/1000\n",
      "966/1000\n",
      "967/1000\n",
      "968/1000\n",
      "969/1000\n",
      "970/1000\n",
      "971/1000\n",
      "972/1000\n",
      "973/1000\n",
      "974/1000\n",
      "975/1000\n",
      "976/1000\n",
      "977/1000\n",
      "978/1000\n",
      "979/1000\n",
      "980/1000\n",
      "981/1000\n",
      "982/1000\n",
      "983/1000\n",
      "984/1000\n",
      "985/1000\n",
      "986/1000\n",
      "987/1000\n",
      "988/1000\n",
      "989/1000\n",
      "990/1000\n",
      "991/1000\n",
      "992/1000\n",
      "993/1000\n",
      "994/1000\n",
      "995/1000\n",
      "996/1000\n",
      "997/1000\n",
      "998/1000\n",
      "999/1000\n",
      "1000/1000\n",
      "auroc 0.8724(0.0088)\n",
      "auprc 0.5363(0.0266)\n",
      "minpse 0.5121(0.0222)\n"
     ]
    }
   ],
   "source": [
    "# Bootstrap\n",
    "N = len(y_true)\n",
    "N_idx = np.arange(N)\n",
    "K = 1000\n",
    "\n",
    "auroc = []\n",
    "auprc = []\n",
    "minpse = []\n",
    "for i in range(K):\n",
    "    boot_idx = np.random.choice(N_idx, N, replace=True)\n",
    "    boot_true = np.array(y_true)[boot_idx]\n",
    "    boot_pred = y_pred[boot_idx, :]\n",
    "    test_ret = metrics.print_metrics_binary(boot_true, boot_pred, verbose=0)\n",
    "    auroc.append(test_ret['auroc'])\n",
    "    auprc.append(test_ret['auprc'])\n",
    "    minpse.append(test_ret['minpse'])\n",
    "    print('%d/%d'%(i+1,K))\n",
    "    \n",
    "print('auroc %.4f(%.4f)'%(np.mean(auroc), np.std(auroc)))\n",
    "print('auprc %.4f(%.4f)'%(np.mean(auprc), np.std(auprc)))\n",
    "print('minpse %.4f(%.4f)'%(np.mean(minpse), np.std(minpse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base1)",
   "language": "python",
   "name": "base1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}